# ============================================================================
# Docker Compose Configuration: Complete Stack with Redis
# ============================================================================
# This configuration provides a complete, ready-to-run setup including:
# - Flask web application
# - Redis for caching and background tasks
# - Watchtower for automatic container updates
#
# Quick Start:
#   1. Copy .env.template to .env and configure settings
#   2. Run: docker-compose up -d
#   3. Access: http://localhost:5000
#
# Redis is included and configured automatically. No external setup needed.
# ============================================================================

services:
  web:
    # Build from local Dockerfile for development
    # build:
    #   context: .
    #   dockerfile: Dockerfile
    # Use the pre-built image from GitHub Container Registry
    image: ghcr.io/qsor27/futurestradinglog:latest
    container_name: futurestradinglog
    ports:
      - "${HOST_IP:-0.0.0.0}:${EXTERNAL_PORT:-5000}:5000"
    volumes:
      - type: bind
        source: ${DATA_DIR:-./data}
        target: /app/data
    environment:
      - FLASK_ENV=${FLASK_ENV:-production}
      - FLASK_DEBUG=${FLASK_DEBUG:-0}
      - DATA_DIR=/app/data
      - FLASK_HOST=0.0.0.0
      - FLASK_PORT=5000
      - FLASK_SECRET_KEY=${FLASK_SECRET_KEY:-dev-secret-key}
      # Redis URL - uses the included redis service by default
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      # Cache enabled by default
      - CACHE_ENABLED=${CACHE_ENABLED:-true}
      # Discord webhook for notifications (optional)
      # Get webhook URL from: Discord Server Settings → Integrations → Webhooks
      # Leave empty to disable Discord notifications
      - DISCORD_WEBHOOK_URL=${DISCORD_WEBHOOK_URL:-}
      # Auto-import settings for NinjaTrader CSV files
      - AUTO_IMPORT_ENABLED=${AUTO_IMPORT_ENABLED:-true}
      - AUTO_IMPORT_INTERVAL=${AUTO_IMPORT_INTERVAL:-300}
    depends_on:
      - redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    labels:
      # Watchtower labels for automatic updates
      - "com.centurylinklabs.watchtower.enable=true"
      - "com.centurylinklabs.watchtower.monitor-only=false"

  # Redis for caching and background tasks
  redis:
    image: redis:7-alpine
    container_name: futurestradinglog-redis
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"

  # Celery worker for background task processing
  celery-worker:
    image: ghcr.io/qsor27/futurestradinglog:latest
    container_name: futurestradinglog-celery-worker
    command: celery -A celery_app worker --loglevel=info --concurrency=2
    volumes:
      - type: bind
        source: ${DATA_DIR:-./data}
        target: /app/data
    environment:
      - FLASK_ENV=${FLASK_ENV:-production}
      - DATA_DIR=/app/data
      - FLASK_SECRET_KEY=${FLASK_SECRET_KEY:-dev-secret-key}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - CACHE_ENABLED=${CACHE_ENABLED:-true}
      - DISCORD_WEBHOOK_URL=${DISCORD_WEBHOOK_URL:-}
    depends_on:
      - redis
      - web
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "celery -A celery_app inspect ping -d celery@$$HOSTNAME"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Celery beat for periodic task scheduling
  celery-beat:
    image: ghcr.io/qsor27/futurestradinglog:latest
    container_name: futurestradinglog-celery-beat
    command: celery -A celery_app beat --loglevel=info
    volumes:
      - type: bind
        source: ${DATA_DIR:-./data}
        target: /app/data
    environment:
      - FLASK_ENV=${FLASK_ENV:-production}
      - DATA_DIR=/app/data
      - FLASK_SECRET_KEY=${FLASK_SECRET_KEY:-dev-secret-key}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - CACHE_ENABLED=${CACHE_ENABLED:-true}
      - DISCORD_WEBHOOK_URL=${DISCORD_WEBHOOK_URL:-}
    depends_on:
      - redis
      - celery-worker
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "test -f celerybeat-schedule"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Watchtower service for automatic container updates
  watchtower:
    image: containrrr/watchtower:latest
    container_name: watchtower
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /etc/localtime:/etc/localtime:ro
    environment:
      # Check for updates every 5 minutes
      - WATCHTOWER_POLL_INTERVAL=300
      # Only monitor containers with the enable label
      - WATCHTOWER_LABEL_ENABLE=true
      # Clean up old images after updating
      - WATCHTOWER_CLEANUP=true
      # Include stopped containers in updates
      - WATCHTOWER_INCLUDE_STOPPED=true
      # Restart containers if they stop unexpectedly
      - WATCHTOWER_REVIVE_STOPPED=true
      # Log level for debugging
      - WATCHTOWER_DEBUG=false
      # Notifications (set to your preferences)
      - WATCHTOWER_NOTIFICATIONS_LEVEL=info
      # Rolling restart (update one container at a time)
      - WATCHTOWER_ROLLING_RESTART=true
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"

volumes:
  redis_data:
