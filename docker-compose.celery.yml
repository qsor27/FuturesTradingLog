version: '3.8'

services:
  # Redis broker for Celery
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Celery worker for general tasks
  celery_worker:
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      - redis
    environment:
      - REDIS_URL=redis://redis:6379/1
      - DATA_DIR=/app/data
      - CACHE_ENABLED=true
    volumes:
      - ./data:/app/data
    command: celery -A celery_app worker --loglevel=info --concurrency=2
    healthcheck:
      test: ["CMD", "celery", "-A", "celery_app", "inspect", "ping"]
      interval: 60s
      timeout: 30s
      retries: 3

  # Celery worker for file processing (separate queue)
  celery_worker_files:
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      - redis
    environment:
      - REDIS_URL=redis://redis:6379/1
      - DATA_DIR=/app/data
      - CACHE_ENABLED=true
    volumes:
      - ./data:/app/data
    command: celery -A celery_app worker --loglevel=info --concurrency=1 --queues=file_processing
    healthcheck:
      test: ["CMD", "celery", "-A", "celery_app", "inspect", "ping"]
      interval: 60s
      timeout: 30s
      retries: 3

  # Celery worker for gap filling (separate queue)
  celery_worker_gaps:
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      - redis
    environment:
      - REDIS_URL=redis://redis:6379/1
      - DATA_DIR=/app/data
      - CACHE_ENABLED=true
    volumes:
      - ./data:/app/data
    command: celery -A celery_app worker --loglevel=info --concurrency=1 --queues=gap_filling
    healthcheck:
      test: ["CMD", "celery", "-A", "celery_app", "inspect", "ping"]
      interval: 60s
      timeout: 30s
      retries: 3

  # Celery worker for position building (separate queue)
  celery_worker_positions:
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      - redis
    environment:
      - REDIS_URL=redis://redis:6379/1
      - DATA_DIR=/app/data
      - CACHE_ENABLED=true
    volumes:
      - ./data:/app/data
    command: celery -A celery_app worker --loglevel=info --concurrency=1 --queues=position_building
    healthcheck:
      test: ["CMD", "celery", "-A", "celery_app", "inspect", "ping"]
      interval: 60s
      timeout: 30s
      retries: 3

  # Celery Beat scheduler for periodic tasks
  celery_beat:
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      - redis
    environment:
      - REDIS_URL=redis://redis:6379/1
      - DATA_DIR=/app/data
      - CACHE_ENABLED=true
    volumes:
      - ./data:/app/data
      - beat_data:/app/beat
    command: celery -A celery_app beat --loglevel=info --schedule=/app/beat/celerybeat-schedule
    healthcheck:
      test: ["CMD", "ps", "aux", "|", "grep", "[c]elery"]
      interval: 60s
      timeout: 30s
      retries: 3

  # Celery Flower for monitoring (optional)
  celery_flower:
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      - redis
    environment:
      - REDIS_URL=redis://redis:6379/1
    ports:
      - "5555:5555"
    command: celery -A celery_app flower --port=5555 --broker=redis://redis:6379/1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5555/"]
      interval: 60s
      timeout: 30s
      retries: 3

  # Main Flask application (updated to work with Celery)
  app:
    build:
      context: .
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      - redis
      - celery_worker
    environment:
      - REDIS_URL=redis://redis:6379/1
      - DATA_DIR=/app/data
      - CACHE_ENABLED=true
      - AUTO_IMPORT_ENABLED=false  # Disabled since Celery handles this
    ports:
      - "5000:5000"
    volumes:
      - ./data:/app/data
    command: python app.py
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  redis_data:
    driver: local
  beat_data:
    driver: local

networks:
  default:
    name: futures_trading_network