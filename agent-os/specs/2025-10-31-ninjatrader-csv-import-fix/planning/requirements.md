# Spec Requirements: NinjaTrader CSV Import Fix

## Initial Description

The user needs to fix the NinjaTrader CSV import process that has ongoing reliability issues. Despite multiple previous spec attempts (2025-09-11-unified-csv-import, 2025-10-08-unified-csv-import, 2025-10-03-csv-import-reliability), there are still constant issues with:
- Automatic import when files arrive
- Import when files are updated throughout the day
- Manual import failures with "File not found or invalid type" errors

The goal is to create a cohesive, reliable system that can ingest trade execution data from NinjaTrader throughout the trading day via CSV files generated by the ExecutionExporter indicator.

## Requirements Discussion

### First Round Questions

**Q1: What specific error is occurring with manual imports?**
**Answer:** The screenshot (importerroroncsv-manager.png) shows "File not found or invalid type" errors for multiple CSV files when attempting manual import through the web interface. The import results show "0 successful, 6 failed" with each file displaying "File not found or invalid type" even though the files are listed in the interface.

**Q2: Where are CSV files being placed and where should the system watch for them?**
**Answer:**
- CSV files are pasted into `C:\Projects\FuturesTradingLog\data` folder
- System should watch ONLY the `data` folder (not archive)
- Files should remain in `data` folder until: (a) successful import AND (b) next day arrives
- Files only move to `archive` after both conditions are met
- NinjaTrader may continue writing to the current day's file throughout the trading day

**Q3: How should the system handle multiple trading accounts?**
**Answer:**
- CRITICAL: Each position is tied to EXACTLY ONE account
- If 2 accounts exist, there can be 2 simultaneous but SEPARATE positions for the same instrument
- Each account tracks times, prices, quantities completely independently
- Positions must NEVER be combined across accounts
- Account separation is fundamental to the position tracking logic

**Q4: What needs to be removed from the UI after this is working?**
**Answer:** After full testing and user confirmation:
- Remove all manual upload forms
- Remove "Import CSV" buttons
- Remove old CSV configuration pages
- Remove multiple import method selectors
- This cleanup is the LAST STEP - only after everything is tested and confirmed working

**Q5: When should the background watcher service start?**
**Answer:** Auto-start on application startup (whether via `python app.py` or `docker-compose up`) as a background thread.

**Q6: How should historical CSVs be re-imported?**
**Answer:** Provide a one-time database command that can be run directly to re-import all historical CSV files from the archive.

**Q7: How quickly should positions update after trades arrive?**
**Answer:** 30-60 seconds is acceptable. Only implement 1-5 second updates if there is NO significant performance cost (i.e., don't over-engineer this).

**Q8: How should the system handle file updates to prevent duplicate executions?**
**Answer:** User wants the cleanest approach that prevents duplicate executions. Suggested approach: incremental processing of only new rows (track last processed row count or execution IDs).

### Existing Code to Reference

**Similar Features Identified:**

The codebase has multiple CSV import services that need consolidation:
- `services/csv_watcher_service.py` - File watching functionality
- `services/import_service.py` - Import logic
- `services/unified_csv_import_service.py` - Unified import attempt
- `services/file_processing/csv_processor.py` - CSV processing logic

Position building service with existing bugs:
- `services/enhanced_position_service_v2.py` - Handles position building but has account-specific tracking issues

NinjaTrader indicator source:
- `ninjascript/ExecutionExporter.cs` - Generates the CSV files with proper account tracking

**Backend logic to reference:**
- Position tracking algorithms in enhanced_position_service_v2.py (needs account-specific fixes)
- Execution deduplication patterns (need to be preserved/enhanced)
- Quantity flow analysis (0 -> +/- -> 0 lifecycle detection)

**Components to potentially consolidate:**
- Multiple import services into single, cohesive system
- File watching with incremental processing
- Deduplication logic using execution IDs

### Follow-up Questions

**Follow-up 1:** I found `importerroroncsv-manager.png` in the visuals folder showing the manual import failures. This helps clarify the UI issues. The screenshot shows 6 files failing with "File not found or invalid type" errors. Based on the NinjaTrader indicator code, the files should be named `NinjaTrader_Executions_YYYYMMDD.csv`. Is the system looking in the wrong directory or is there a file path resolution issue?

**Answer:** Yes, there appears to be a path resolution issue. The files exist in the `data` folder but the import system cannot find them. This needs to be fixed as part of the unified import system.

**Follow-up 2:** The ExecutionExporter.cs indicator already tracks positions per account (line 269-276, 379-382). Should the Python import system trust this tracking or recalculate positions independently?

**Answer:** The Python system should recalculate positions independently based on the execution data. The indicator's Entry/Exit markers are helpful but the position builder needs to analyze the full execution flow per account to build accurate positions.

**Follow-up 3:** For incremental processing, should the system track the last processed execution ID per file, or track row count, or use file modification timestamp?

**Answer:** Use execution ID tracking (column "ID" in the CSV). This is most reliable since the indicator uses unique execution IDs and prevents duplicate processing even if files are re-imported.

## Visual Assets

### Files Provided:
- `importerroroncsv-manager.png`: Screenshot of the CSV manager interface showing manual import failures

### Visual Insights:

**From importerroroncsv-manager.png:**
- Interface shows "NinjaTrader Executions: Raw export files from NinjaTrader (will be automatically processed)"
- Section for "Processed TradeLog: Already processed CSV files with positions and P&L data"
- Shows 91 total CSV files, 6 selected files totaling 1.00 MB
- Import buttons: "Select All", "Select None", "Select Recent (Last 7 Days)", "Import Selected Files"
- Import results display: "0 successful, 6 failed, Total: 6"
- Each failed file shows "File not found or invalid type" error
- Failed files are named in format: `NinjaTrader_Executions_YYYYMMDD.csv` (dates: 20251030, 20251029, 20251028, 20251027, 20251024, 20251031)
- File list shows checked items including the failed files
- Interface has a table structure with checkboxes and filenames

**Design Implications:**
- Current manual import UI will be removed after automatic system is working
- File detection/path resolution is broken in current implementation
- System needs to properly locate files in the `data` directory
- Automatic processing should eliminate need for manual intervention shown in screenshot

**Fidelity level:** High-fidelity screenshot of existing production interface

## Requirements Summary

### Functional Requirements

**Core Import Functionality:**
- Automatically detect and import CSV files from `C:\Projects\FuturesTradingLog\data` folder
- Process files incrementally (only new executions) to prevent duplicates
- Use execution ID (column "ID") for deduplication tracking
- Handle files that are continuously updated throughout trading day
- Move files to archive only after: (a) successful import AND (b) next day
- Process executions and build positions with 30-60 second latency (acceptable)

**Account-Specific Position Tracking:**
- Track positions completely separately per account (CRITICAL requirement)
- Never combine positions from different accounts
- Each account maintains independent: times, prices, quantities, position state
- Properly detect position opens (quantity moves from 0) and closes (quantity returns to 0)
- Handle simultaneous positions in same instrument across different accounts

**File Management:**
- Watch only the `data` folder (not archive)
- Leave files in `data` until next day AND successful import
- Handle file locking gracefully (NinjaTrader may be writing)
- Support file format: `NinjaTrader_Executions_YYYYMMDD.csv`
- Create archive mechanism after successful import on next day

**Service Lifecycle:**
- Auto-start background watcher on application startup
- Run as background thread/service
- Start whether app launched via `python app.py` or `docker-compose up`
- Graceful shutdown and cleanup on application termination

**Historical Data Re-import:**
- Provide database command for one-time re-import of all historical CSVs
- Process all files from archive in chronological order
- Rebuild positions from scratch based on historical data

**CSV Format Support:**
- Header: `Instrument,Action,Quantity,Price,Time,ID,E/X,Position,Order ID,Name,Commission,Rate,Account,Connection,`
- Columns of importance:
  - Instrument: Contract specification (e.g., "MNQ DEC25")
  - Action: Buy, Sell, BuyToCover, SellShort
  - Quantity: Absolute quantity (always positive)
  - Price: Execution price
  - Time: Execution timestamp (format: "M/d/yyyy h:mm:ss tt")
  - ID: Unique execution identifier (e.g., "303363433426_1")
  - E/X: Entry or Exit marker from indicator
  - Position: Current position after execution (e.g., "6 L", "3 S", "-")
  - Account: Account identifier (e.g., "APEX1279810000057")
  - Commission: Commission charged

**Position Building Logic:**
- Detect position start: quantity moves from 0 to non-zero
- Detect position end: quantity returns to 0
- Track quantity flow per account independently
- Handle position scaling (adding/reducing)
- Handle position reversals (long to short or vice versa)
- Properly pair executions within same position per account
- Calculate accurate P&L using futures multipliers

### Reusability Opportunities

**Existing Code Patterns:**
- Position building algorithm from `enhanced_position_service_v2.py` (needs account-specific fix)
- File watching patterns from `csv_watcher_service.py`
- CSV parsing logic from existing import services
- Execution deduplication approach (enhance with execution ID tracking)
- Background service architecture (Celery/threading patterns)
- Redis caching layer (can cache processed execution IDs)
- SQLite database with WAL mode and indexes

**Components to Consolidate:**
- Merge: `csv_watcher_service.py`, `import_service.py`, `unified_csv_import_service.py`, `csv_processor.py`
- Create single cohesive import service with clear responsibilities
- Remove duplicate/conflicting logic
- Simplify codebase maintenance

**NinjaTrader Indicator Integration:**
- Indicator already exports in correct format
- Indicator handles execution-level deduplication
- Indicator provides Entry/Exit hints (use as guidance, not truth)
- Indicator tracks position per account (use as validation reference)

### Scope Boundaries

**In Scope:**
- Single, unified CSV import system
- Automatic file detection and processing from `data` folder
- Incremental processing with execution ID deduplication
- Account-specific position tracking and building
- File archival after successful import + next day
- Background service auto-start
- Historical data re-import command
- Fix manual import path resolution issues
- 30-60 second update latency
- Graceful handling of file locks and partial writes

**Out of Scope (for this spec):**
- Removing old import UI (LAST STEP, after testing, separate cleanup task)
- Real-time position updates (1-5 seconds only if no performance cost)
- Multi-threading/parallel processing (unless needed for 30-60s target)
- Advanced error recovery UIs
- Position linking between accounts (future Phase 3 feature per roadmap)
- Email/push notifications on import failures
- Automatic position rebuilds (separate spec: 2025-09-09-auto-trade-position-transform)

**Explicitly Excluded:**
- Modifying the NinjaTrader ExecutionExporter.cs indicator
- Changing CSV file format or structure
- Processing files from locations other than `data` folder
- Manual import UI improvements (will be removed later)
- Advanced scheduling or time-based processing rules
- External integrations or webhooks

### Technical Considerations

**Integration Points:**
- SQLite database for execution and position storage
- Redis cache for processed execution ID tracking
- Background service framework (Celery or threading)
- File system monitoring (watchdog library or polling)
- Flask application lifecycle hooks for service startup

**Existing System Constraints:**
- SQLite with WAL mode and 8 aggressive indexes
- Redis with 14-day retention
- Flask 3.0.0 with Blueprint-based routing
- Pandas 2.1.4 for data manipulation
- Docker containerization with automated deployments
- Must maintain existing 15-50ms chart load performance
- Cannot break existing position-based analytics

**Technology Preferences:**
- Python for all import logic
- Pandas for CSV processing
- SQLAlchemy for database operations
- Redis for execution ID cache (prevent reprocessing)
- Threading or Celery for background tasks
- Watchdog or polling for file monitoring

**Similar Code Patterns to Follow:**
- Position-based architecture (quantity flow: 0 -> +/- -> 0)
- Background service patterns from existing Celery setup
- Error handling and logging standards from current codebase
- Blueprint-based routing structure
- Pydantic models for data validation
- Structured logging with rotation

**Performance Requirements:**
- 30-60 second latency from file update to position update (acceptable)
- Maintain existing 15-50ms chart load times
- Minimal memory footprint for background watcher
- Efficient incremental processing (don't reprocess entire files)
- Redis TTL for execution ID cache (14-day retention matches existing pattern)

**Data Integrity:**
- Execution ID-based deduplication prevents duplicates
- Account-specific position tracking prevents cross-account contamination
- Transaction-based database updates for atomic position creation
- File archival only after confirmed successful import
- Validation of CSV structure before processing

**Reliability Requirements:**
- Graceful handling of file locks (NinjaTrader may be writing)
- Retry mechanism for transient failures
- Comprehensive error logging for debugging
- Health check endpoint for monitoring
- Recovery from partial imports
- Safe restart without data loss or duplicate processing
