"""
Daily Import Scheduler Service

Implements the daily import strategy for futures trading data:
- Automatic import at 2:05pm Pacific (5:05pm Eastern) when market closes
- Manual import trigger via API endpoint
- Import validation (date matching, closed positions only)

Futures Market Schedule:
- Trading Hours: 23 hours/day, 5 days/week
- Sessions: Sunday 3pm PT → Monday 2pm PT, Monday 3pm PT → Tuesday 2pm PT, etc.
- Data Export: NinjaTrader exports with CLOSING date (e.g., Monday session closes at 2pm = Monday's date)

Task Group 4: Daily Import Strategy Implementation
"""

import logging
import threading
import time
from datetime import datetime, time as dt_time
from pathlib import Path
from typing import Dict, Any, Optional, List
import schedule
import pytz

from config import config
from services.ninjatrader_import_service import NinjaTraderImportService
from services.data_service import ohlc_service
from services.instrument_mapper import InstrumentMapper

logger = logging.getLogger('DailyImportScheduler')


class DailyImportScheduler:
    """
    Service for scheduling daily imports at market close (2:05pm Pacific).

    Features:
    - Scheduled import at 2:05pm PT daily (if app is running)
    - Manual import trigger via API
    - Import validation (date matching, closed positions only)
    - Timezone-aware scheduling (Pacific Time)
    """

    # Market close time: 2:00pm Pacific (5:00pm Eastern)
    # Import scheduled for 2:05pm Pacific to allow NinjaTrader export to complete
    IMPORT_TIME_PT = "14:05"  # 2:05pm Pacific

    def __init__(self, data_dir: Optional[Path] = None):
        """
        Initialize the daily import scheduler.

        Args:
            data_dir: Directory containing CSV files (default: config.data_dir)
        """
        self.data_dir = data_dir or config.data_dir
        self.import_service = NinjaTraderImportService(data_dir=self.data_dir)

        # OHLC sync services
        self.ohlc_service = ohlc_service
        self.instrument_mapper = InstrumentMapper()

        # Scheduler state
        self._scheduler_thread: Optional[threading.Thread] = None
        self._stop_event = threading.Event()
        self._running = False

        # Import history
        self.last_scheduled_import: Optional[datetime] = None
        self.last_manual_import: Optional[datetime] = None
        self.import_history: List[Dict[str, Any]] = []

        # Timezone
        self.pacific_tz = pytz.timezone('America/Los_Angeles')

        logger.info("DailyImportScheduler initialized")

        # Validate configuration at startup
        self._validate_timezone_config()
        self._validate_redis_connection()
        logger.info(f"Scheduled import time: {self.IMPORT_TIME_PT} PT")


    def _validate_redis_connection(self) -> bool:
        """
        Validate Redis connectivity at startup.

        Returns:
            True if Redis is accessible, False otherwise
        """
        try:
            # Only validate if cache is enabled
            if not config.cache_enabled:
                logger.warning("=" * 80)
                logger.warning("CACHE_ENABLED is set to false")
                logger.warning("OHLC data sync requires Redis caching to function properly")
                logger.warning("Troubleshooting:")
                logger.warning("  1. Set CACHE_ENABLED=true in .env file")
                logger.warning("  2. Ensure REDIS_URL points to correct Redis instance")
                logger.warning("  3. For Docker: use REDIS_URL=redis://redis:6379/0")
                logger.warning("  4. For local: use REDIS_URL=redis://localhost:6379/0")
                logger.warning("=" * 80)
                return False

            # Test Redis connection
            import redis
            redis_client = redis.Redis.from_url(config.redis_url)
            redis_client.ping()

            logger.info(f"Redis connection successful: {config.redis_url}")
            return True

        except Exception as e:
            logger.error("=" * 80)
            logger.error("Redis connection failed!")
            logger.error(f"Error: {e}")
            logger.error(f"Redis URL: {config.redis_url}")
            logger.error("Troubleshooting:")
            logger.error("  1. Verify Redis service is running")
            logger.error("  2. Check REDIS_URL in .env file")
            logger.error("  3. For Docker: use 'redis' as hostname (redis://redis:6379/0)")
            logger.error("  4. For local: use 'localhost' (redis://localhost:6379/0)")
            logger.error("  5. Ensure containers are on the same Docker network")
            logger.error("=" * 80)
            return False

    def _validate_timezone_config(self) -> bool:
        """
        Validate timezone configuration (Pacific Time).

        Returns:
            True if timezone is properly configured
        """
        try:
            # Verify Pacific timezone is set
            if self.pacific_tz.zone != 'America/Los_Angeles':
                logger.error(f"Timezone misconfigured! Expected 'America/Los_Angeles', got '{self.pacific_tz.zone}'")
                return False

            # Log current time in both UTC and Pacific
            now_utc = datetime.now(pytz.UTC)
            now_pt = datetime.now(self.pacific_tz)

            logger.info("Timezone configuration validated:")
            logger.info(f"  - Pacific Time: {now_pt.strftime('%Y-%m-%d %H:%M:%S %Z')}")
            logger.info(f"  - UTC Time: {now_utc.strftime('%Y-%m-%d %H:%M:%S %Z')}")
            logger.info(f"  - Scheduled import: {self.IMPORT_TIME_PT} PT (22:05 UTC)")

            return True

        except Exception as e:
            logger.error(f"Timezone validation failed: {e}", exc_info=True)
            return False

    def start(self):
        """
        Start the daily import scheduler.

        This starts a background thread that runs the schedule checker.
        The scheduler will automatically import at 2:05pm PT each day.
        """
        if self._running:
            logger.warning("Daily import scheduler is already running")
            return

        logger.info("Starting daily import scheduler...")

        # Clear any existing schedule
        schedule.clear()

        # Schedule daily import at 2:05pm Pacific
        schedule.every().day.at(self.IMPORT_TIME_PT).do(self._scheduled_import_callback)

        # Start scheduler thread
        self._stop_event.clear()
        self._scheduler_thread = threading.Thread(
            target=self._scheduler_loop,
            name="DailyImportScheduler",
            daemon=True
        )
        self._scheduler_thread.start()

        self._running = True
        logger.info("Daily import scheduler started successfully")
        logger.info(f"Next scheduled import: {self._get_next_import_time()}")

    def stop(self):
        """Stop the daily import scheduler."""
        if not self._running:
            logger.warning("Daily import scheduler is not running")
            return

        logger.info("Stopping daily import scheduler...")

        # Signal thread to stop
        self._stop_event.set()

        # Wait for thread to finish (with timeout)
        if self._scheduler_thread and self._scheduler_thread.is_alive():
            self._scheduler_thread.join(timeout=5.0)

        # Clear schedule
        schedule.clear()

        self._running = False
        logger.info("Daily import scheduler stopped")

    def _scheduler_loop(self):
        """Background thread loop for running scheduled tasks."""
        logger.info("Scheduler thread started")

        while not self._stop_event.is_set():
            try:
                # Run pending scheduled tasks
                schedule.run_pending()

                # Sleep for 30 seconds before next check
                time.sleep(30)

            except Exception as e:
                logger.error(f"Error in scheduler loop: {e}", exc_info=True)
                time.sleep(60)  # Wait longer after error

        logger.info("Scheduler thread stopped")

    def _scheduled_import_callback(self):
        """
        Callback for scheduled daily import.

        This is called automatically at 2:05pm PT each day.
        """
        logger.info("=" * 80)
        logger.info("SCHEDULED DAILY IMPORT TRIGGERED")
        logger.info(f"Time: {datetime.now(self.pacific_tz).strftime('%Y-%m-%d %H:%M:%S %Z')}")
        logger.info("=" * 80)

        try:
            result = self._perform_daily_import(is_manual=False)

            # Record import
            self.last_scheduled_import = datetime.now(self.pacific_tz)
            self._record_import_history(result, is_manual=False)

            if result['success']:
                logger.info("✓ Scheduled daily import completed successfully")
                logger.info(f"  - Files processed: {result.get('files_processed', 0)}")
                logger.info(f"  - Executions imported: {result.get('total_executions', 0)}")
                logger.info(f"  - Positions rebuilt: {result.get('positions_rebuilt', 0)}")
            else:
                logger.error(f"✗ Scheduled daily import failed: {result.get('error', 'Unknown error')}")

        except Exception as e:
            logger.error(f"Error in scheduled import callback: {e}", exc_info=True)
            self._record_import_history({
                'success': False,
                'error': str(e)
            }, is_manual=False)

    def manual_import(self, specific_date: Optional[str] = None) -> Dict[str, Any]:
        """
        Trigger manual import.

        Args:
            specific_date: Optional specific date to import (YYYYMMDD format)
                          If None, imports today's file

        Returns:
            Dict with import results
        """
        logger.info("=" * 80)
        logger.info("MANUAL IMPORT TRIGGERED")
        logger.info(f"Time: {datetime.now(self.pacific_tz).strftime('%Y-%m-%d %H:%M:%S %Z')}")
        if specific_date:
            logger.info(f"Target date: {specific_date}")
        logger.info("=" * 80)

        try:
            result = self._perform_daily_import(
                is_manual=True,
                specific_date=specific_date
            )

            # Record import
            self.last_manual_import = datetime.now(self.pacific_tz)
            self._record_import_history(result, is_manual=True)

            return result

        except Exception as e:
            logger.error(f"Error in manual import: {e}", exc_info=True)
            error_result = {
                'success': False,
                'error': str(e)
            }
            self._record_import_history(error_result, is_manual=True)
            return error_result

    def _extract_instruments_from_csv(self, file_path: Path) -> List[str]:
        """
        Extract unique instrument names from CSV file.

        Args:
            file_path: Path to CSV file

        Returns:
            List of unique instrument names found in CSV
        """
        try:
            import pandas as pd

            # Read CSV file
            df = pd.read_csv(file_path)

            # Extract unique instruments from 'Instrument' column
            if 'Instrument' in df.columns:
                instruments = df['Instrument'].dropna().unique().tolist()
                logger.info(f"Extracted {len(instruments)} unique instruments from CSV")
                return instruments
            else:
                logger.warning("No 'Instrument' column found in CSV")
                return []

        except Exception as e:
            logger.error(f"Error extracting instruments from CSV: {e}")
            return []

    def _trigger_ohlc_sync(self, instruments: List[str], reason: str = "post_import"):
        """
        Trigger OHLC sync for imported instruments.

        Args:
            instruments: List of NinjaTrader instrument names (e.g., ['MNQ 12-24', 'MES 03-25'])
            reason: Reason for sync (for logging)
        """
        try:
            if not instruments:
                logger.info("No instruments to sync - skipping OHLC sync")
                return

            logger.info(f"Triggering OHLC sync for {len(instruments)} instruments...")

            # Map NinjaTrader instruments to Yahoo Finance symbols
            yahoo_symbols = self.instrument_mapper.map_to_yahoo(instruments)

            if not yahoo_symbols:
                logger.warning("No Yahoo Finance symbols mapped - skipping OHLC sync")
                return

            logger.info(f"Mapped to {len(yahoo_symbols)} Yahoo Finance symbols: {', '.join(yahoo_symbols)}")

            # Get all 18 Yahoo Finance timeframes
            timeframes = self.ohlc_service.get_all_yahoo_timeframes()

            # Trigger sync
            sync_stats = self.ohlc_service.sync_instruments(
                instruments=yahoo_symbols,
                timeframes=timeframes,
                reason=reason
            )

            logger.info(f"OHLC sync completed: {sync_stats['candles_added']} candles added "
                       f"in {sync_stats['duration_seconds']:.1f}s")

        except Exception as e:
            # Log error but don't fail the import
            logger.error(f"OHLC sync failed (import still successful): {e}", exc_info=True)

    def _perform_daily_import(self, is_manual: bool = False,
                             specific_date: Optional[str] = None) -> Dict[str, Any]:
        """
        Perform the daily import process.

        Steps:
        1. Determine target date (today's market close or specific date)
        2. Find CSV file matching the date
        3. Validate file (correct date, closed positions only)
        4. Import executions
        5. Rebuild positions for affected accounts
        6. Trigger OHLC sync for imported instruments

        Args:
            is_manual: Whether this is a manual import
            specific_date: Optional specific date to import (YYYYMMDD format)

        Returns:
            Dict with import results
        """
        # Step 1: Determine target date
        if specific_date:
            target_date = specific_date
            logger.info(f"Importing specific date: {target_date}")
        else:
            # Use today's date (market closed today)
            target_date = datetime.now(self.pacific_tz).strftime('%Y%m%d')
            logger.info(f"Importing today's date: {target_date}")

        # Step 2: Find CSV file
        expected_filename = f"NinjaTrader_Executions_{target_date}.csv"
        file_path = self.data_dir / expected_filename

        if not file_path.exists():
            logger.warning(f"CSV file not found: {expected_filename}")
            return {
                'success': False,
                'error': f'CSV file not found: {expected_filename}',
                'expected_file': expected_filename,
                'search_path': str(self.data_dir)
            }

        logger.info(f"Found CSV file: {expected_filename}")

        # Step 3: Validate file
        validation_result = self._validate_import_file(file_path, target_date)
        if not validation_result['valid']:
            logger.error(f"File validation failed: {validation_result['error']}")
            return {
                'success': False,
                'error': f"Validation failed: {validation_result['error']}",
                'validation_details': validation_result
            }

        logger.info("✓ File validation passed")

        # Step 4: Import executions
        logger.info("Importing executions...")
        import_result = self.import_service.process_csv_file(file_path)

        if not import_result['success']:
            logger.error(f"Import failed: {import_result.get('error', 'Unknown error')}")
            return import_result

        logger.info(f"✓ Import successful: {import_result.get('executions_imported', 0)} executions")

        # Step 5: Extract instruments and trigger OHLC sync
        instruments = self._extract_instruments_from_csv(file_path)
        if instruments:
            self._trigger_ohlc_sync(
                instruments=instruments,
                reason="post_import_scheduled" if not is_manual else "post_import_manual"
            )

        # Step 6: Build summary
        return {
            'success': True,
            'import_type': 'manual' if is_manual else 'scheduled',
            'target_date': target_date,
            'filename': expected_filename,
            'files_processed': 1,
            'total_executions': import_result.get('executions_imported', 0),
            'positions_rebuilt': import_result.get('positions_rebuilt', 0),
            'accounts_affected': import_result.get('accounts_affected', []),
            'instruments_affected': import_result.get('instruments_affected', []),
            'instruments_synced': len(instruments),
            'timestamp': datetime.now(self.pacific_tz).isoformat()
        }

    def _validate_import_file(self, file_path: Path, expected_date: str) -> Dict[str, Any]:
        """
        Validate CSV file before import.

        Validation checks:
        1. Filename matches expected date
        2. File is not empty
        3. All positions in file are closed (no open positions)

        Args:
            file_path: Path to CSV file
            expected_date: Expected date in YYYYMMDD format

        Returns:
            Dict with validation result
        """
        try:
            # Check 1: Filename matches expected date
            filename_date = file_path.stem.split('_')[-1]  # Extract date from filename
            if filename_date != expected_date:
                return {
                    'valid': False,
                    'error': f'Filename date mismatch. Expected: {expected_date}, Got: {filename_date}'
                }

            # Check 2: File is not empty
            if file_path.stat().st_size == 0:
                return {
                    'valid': False,
                    'error': 'File is empty'
                }

            # Check 3: All positions are closed
            # This validation is optional - we rely on the position builder to handle this
            # For now, we just check that the file is readable

            return {
                'valid': True,
                'filename_date': filename_date,
                'file_size': file_path.stat().st_size
            }

        except Exception as e:
            logger.error(f"Error validating file: {e}", exc_info=True)
            return {
                'valid': False,
                'error': f'Validation error: {str(e)}'
            }

    def _record_import_history(self, result: Dict[str, Any], is_manual: bool):
        """
        Record import in history.

        Args:
            result: Import result dictionary
            is_manual: Whether this was a manual import
        """
        history_entry = {
            'timestamp': datetime.now(self.pacific_tz).isoformat(),
            'type': 'manual' if is_manual else 'scheduled',
            'success': result.get('success', False),
            'files_processed': result.get('files_processed', 0),
            'executions_imported': result.get('total_executions', 0),
            'error': result.get('error')
        }

        self.import_history.append(history_entry)

        # Keep only last 100 imports
        if len(self.import_history) > 100:
            self.import_history = self.import_history[-100:]

    def get_status(self) -> Dict[str, Any]:
        """
        Get scheduler status.

        Returns:
            Dict with scheduler state and statistics
        """
        now_pt = datetime.now(self.pacific_tz)

        return {
            'running': self._running,
            'scheduled_import_time': self.IMPORT_TIME_PT + ' PT',
            'next_scheduled_import': self._get_next_import_time(),
            'last_scheduled_import': self.last_scheduled_import.isoformat() if self.last_scheduled_import else None,
            'last_manual_import': self.last_manual_import.isoformat() if self.last_manual_import else None,
            'current_time_pt': now_pt.strftime('%Y-%m-%d %H:%M:%S %Z'),
            'import_history_count': len(self.import_history),
            'recent_imports': self.import_history[-5:] if self.import_history else []
        }

    def _get_next_import_time(self) -> Optional[str]:
        """Get next scheduled import time."""
        try:
            next_run = schedule.next_run()
            if next_run:
                # Convert to Pacific Time
                next_run_pt = next_run.replace(tzinfo=pytz.UTC).astimezone(self.pacific_tz)
                return next_run_pt.strftime('%Y-%m-%d %H:%M:%S %Z')
            return None
        except Exception:
            return None

    def is_running(self) -> bool:
        """Check if scheduler is running."""
        return self._running


# Global instance
daily_import_scheduler = DailyImportScheduler()
